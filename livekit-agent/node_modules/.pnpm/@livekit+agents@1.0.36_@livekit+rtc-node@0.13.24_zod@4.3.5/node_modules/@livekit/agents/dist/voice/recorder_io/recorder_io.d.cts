import { AudioFrame } from '@livekit/rtc-node';
import type { AgentSession } from '../agent_session.js';
import { AudioInput, AudioOutput, type PlaybackFinishedEvent } from '../io.js';
export interface RecorderOptions {
    agentSession: AgentSession;
    sampleRate?: number;
}
export declare class RecorderIO {
    private inRecord?;
    private outRecord?;
    private inChan;
    private outChan;
    private session;
    private sampleRate;
    private _outputPath?;
    private forwardTask?;
    private encodeTask?;
    private closeFuture;
    private lock;
    private started;
    private pcmStream?;
    private ffmpegPromise?;
    private inResampler?;
    private outResampler?;
    private logger;
    constructor(opts: RecorderOptions);
    start(outputPath: string): Promise<void>;
    close(): Promise<void>;
    recordInput(audioInput: AudioInput): RecorderAudioInput;
    recordOutput(audioOutput: AudioOutput): RecorderAudioOutput;
    private writeCb;
    get recording(): boolean;
    get outputPath(): string | undefined;
    get recordingStartedAt(): number | undefined;
    /**
     * Forward task: periodically flush input buffer to encoder
     */
    private forward;
    /**
     * Start FFmpeg process for streaming encoding
     */
    private startFFmpeg;
    /**
     * Resample and mix frames to mono Float32
     */
    private resampleAndMix;
    /**
     * Write PCM chunk to FFmpeg stream
     */
    private writePCM;
    /**
     * Encode task: read from channels, mix to stereo, stream to FFmpeg
     */
    private encode;
}
declare class RecorderAudioInput extends AudioInput {
    private source;
    private recorderIO;
    private accFrames;
    private _startedWallTime?;
    constructor(recorderIO: RecorderIO, source: AudioInput);
    /**
     * Wall-clock time when the first frame was captured
     */
    get startedWallTime(): number | undefined;
    /**
     * Take accumulated frames and clear the buffer
     */
    takeBuf(): AudioFrame[];
    /**
     * Creates a stream that intercepts frames from the source,
     * accumulates them when recording, and passes them through unchanged.
     */
    private createInterceptingStream;
    onAttached(): void;
    onDetached(): void;
}
declare class RecorderAudioOutput extends AudioOutput {
    private recorderIO;
    private writeFn;
    private accFrames;
    private _startedWallTime?;
    private currentPauseStart?;
    private pauseWallTimes;
    constructor(recorderIO: RecorderIO, audioOutput: AudioOutput, writeFn: (buf: AudioFrame[]) => void);
    get startedWallTime(): number | undefined;
    get hasPendingData(): boolean;
    pause(): void;
    /**
     * Resume playback and record the pause interval
     */
    resume(): void;
    private resetPauseState;
    onPlaybackFinished(options: PlaybackFinishedEvent): void;
    captureFrame(frame: AudioFrame): Promise<void>;
    flush(): void;
    clearBuffer(): void;
}
export {};
//# sourceMappingURL=recorder_io.d.ts.map