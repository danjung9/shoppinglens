import { beforeAll, describe, expect, it, vi } from "vitest";
import { APIConnectionError, APIError } from "../_exceptions.js";
import { initializeLogger } from "../log.js";
import { delay } from "../utils.js";
import { FallbackAdapter } from "./fallback_adapter.js";
import { LLM, LLMStream } from "./llm.js";
class MockLLMStream extends LLMStream {
  constructor(llm, opts, shouldFail = false, failAfterChunks = 0) {
    super(llm, opts);
    this.shouldFail = shouldFail;
    this.failAfterChunks = failAfterChunks;
    this.myLLM = llm;
  }
  myLLM;
  async run() {
    if (this.shouldFail && this.failAfterChunks === 0) {
      throw new APIError("Mock LLM failed immediately");
    }
    const chunk = {
      id: "test-id",
      delta: { role: "assistant", content: "chunk" }
    };
    for (let i = 0; i < 3; i++) {
      if (this.shouldFail && i === this.failAfterChunks) {
        throw new APIError("Mock LLM failed after chunks");
      }
      this.queue.put(chunk);
      await delay(10);
    }
  }
}
class MockLLM extends LLM {
  shouldFail = false;
  failAfterChunks = 0;
  _label;
  constructor(label) {
    super();
    this._label = label;
  }
  label() {
    return this._label;
  }
  chat(opts) {
    return new MockLLMStream(
      this,
      {
        chatCtx: opts.chatCtx,
        toolCtx: opts.toolCtx,
        connOptions: opts.connOptions
      },
      this.shouldFail,
      this.failAfterChunks
    );
  }
}
describe("FallbackAdapter", () => {
  beforeAll(() => {
    initializeLogger({ pretty: false });
    process.on("unhandledRejection", () => {
    });
  });
  it("should initialize correctly", () => {
    const llm1 = new MockLLM("llm1");
    const adapter = new FallbackAdapter({ llms: [llm1] });
    expect(adapter.llms).toHaveLength(1);
    expect(adapter.llms[0]).toBe(llm1);
  });
  it("should throw if no LLMs provided", () => {
    expect(() => new FallbackAdapter({ llms: [] })).toThrow();
  });
  it("should use primary LLM if successful", async () => {
    const llm1 = new MockLLM("llm1");
    const llm2 = new MockLLM("llm2");
    const adapter = new FallbackAdapter({ llms: [llm1, llm2] });
    const stream = adapter.chat({
      chatCtx: {}
    });
    const chunks = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    expect(chunks).toHaveLength(3);
  });
  it("should fallback to second LLM if first fails immediately", async () => {
    const llm1 = new MockLLM("llm1");
    llm1.shouldFail = true;
    const llm2 = new MockLLM("llm2");
    const adapter = new FallbackAdapter({ llms: [llm1, llm2] });
    const stream = adapter.chat({
      chatCtx: {}
    });
    const chunks = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    expect(chunks).toHaveLength(3);
    expect(adapter._status[0].available).toBe(false);
    expect(adapter._status[1].available).toBe(true);
  });
  it("should fail if all LLMs fail", async () => {
    const llm1 = new MockLLM("llm1");
    llm1.shouldFail = true;
    const llm2 = new MockLLM("llm2");
    llm2.shouldFail = true;
    const adapter = new FallbackAdapter({ llms: [llm1, llm2] });
    const stream = adapter.chat({
      chatCtx: {}
    });
    const errorPromise = new Promise((resolve) => {
      adapter.on("error", (e) => resolve(e.error));
    });
    for await (const _ of stream) {
    }
    const error = await errorPromise;
    expect(error).toBeInstanceOf(APIConnectionError);
  });
  it("should fail if chunks sent and retryOnChunkSent is false", async () => {
    const llm1 = new MockLLM("llm1");
    llm1.shouldFail = true;
    llm1.failAfterChunks = 1;
    const llm2 = new MockLLM("llm2");
    const adapter = new FallbackAdapter({
      llms: [llm1, llm2],
      retryOnChunkSent: false
    });
    const stream = adapter.chat({
      chatCtx: {}
    });
    const errorPromise = new Promise((resolve) => {
      adapter.on("error", (e) => resolve(e.error));
    });
    for await (const _ of stream) {
    }
    const error = await errorPromise;
    expect(error).toBeInstanceOf(APIError);
  });
  it("should fallback if chunks sent and retryOnChunkSent is true", async () => {
    const llm1 = new MockLLM("llm1");
    llm1.shouldFail = true;
    llm1.failAfterChunks = 1;
    const llm2 = new MockLLM("llm2");
    const adapter = new FallbackAdapter({
      llms: [llm1, llm2],
      retryOnChunkSent: true
    });
    const stream = adapter.chat({
      chatCtx: {}
    });
    const chunks = [];
    for await (const chunk of stream) {
      chunks.push(chunk);
    }
    expect(chunks).toHaveLength(4);
  });
  it("should emit availability changed events", async () => {
    const llm1 = new MockLLM("llm1");
    llm1.shouldFail = true;
    const llm2 = new MockLLM("llm2");
    const adapter = new FallbackAdapter({ llms: [llm1, llm2] });
    const eventSpy = vi.fn();
    adapter.on("llm_availability_changed", eventSpy);
    const stream = adapter.chat({
      chatCtx: {}
    });
    for await (const _ of stream) {
    }
    expect(eventSpy).toHaveBeenCalledWith(
      expect.objectContaining({
        llm: llm1,
        available: false
      })
    );
  });
});
//# sourceMappingURL=fallback_adapter.test.js.map