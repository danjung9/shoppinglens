{"version":3,"sources":["../../src/inference/llm.ts"],"sourcesContent":["// SPDX-FileCopyrightText: 2025 LiveKit, Inc.\n//\n// SPDX-License-Identifier: Apache-2.0\nimport OpenAI from 'openai';\nimport {\n  APIConnectionError,\n  APIStatusError,\n  APITimeoutError,\n  DEFAULT_API_CONNECT_OPTIONS,\n  type Expand,\n  toError,\n} from '../index.js';\nimport * as llm from '../llm/index.js';\nimport type { APIConnectOptions } from '../types.js';\nimport { type AnyString, createAccessToken } from './utils.js';\n\nconst DEFAULT_BASE_URL = 'https://agent-gateway.livekit.cloud/v1';\n\nexport type OpenAIModels =\n  | 'openai/gpt-5'\n  | 'openai/gpt-5-mini'\n  | 'openai/gpt-5-nano'\n  | 'openai/gpt-4.1'\n  | 'openai/gpt-4.1-mini'\n  | 'openai/gpt-4.1-nano'\n  | 'openai/gpt-4o'\n  | 'openai/gpt-4o-mini'\n  | 'openai/gpt-oss-120b';\n\nexport type GoogleModels =\n  | 'google/gemini-3-pro-preview'\n  | 'google/gemini-3-flash-preview'\n  | 'google/gemini-2.5-pro'\n  | 'google/gemini-2.5-flash'\n  | 'google/gemini-2.5-flash-lite'\n  | 'google/gemini-2.0-flash'\n  | 'google/gemini-2.0-flash-lite';\n\nexport type QwenModels = 'qwen/qwen3-235b-a22b-instruct';\n\nexport type KimiModels = 'moonshotai/kimi-k2-instruct';\n\nexport type DeepSeekModels = 'deepseek-ai/deepseek-v3';\n\ntype ChatCompletionPredictionContentParam =\n  Expand<OpenAI.Chat.Completions.ChatCompletionPredictionContent>;\ntype WebSearchOptions = Expand<OpenAI.Chat.Completions.ChatCompletionCreateParams.WebSearchOptions>;\ntype ToolChoice = Expand<OpenAI.Chat.Completions.ChatCompletionCreateParams['tool_choice']>;\ntype Verbosity = 'low' | 'medium' | 'high';\n\nexport interface ChatCompletionOptions extends Record<string, unknown> {\n  frequency_penalty?: number;\n  logit_bias?: Record<string, number>;\n  logprobs?: boolean;\n  max_completion_tokens?: number;\n  max_tokens?: number;\n  metadata?: Record<string, string>;\n  modalities?: Array<'text' | 'audio'>;\n  n?: number;\n  parallel_tool_calls?: boolean;\n  prediction?: ChatCompletionPredictionContentParam | null;\n  presence_penalty?: number;\n  prompt_cache_key?: string;\n  reasoning_effort?: 'minimal' | 'low' | 'medium' | 'high';\n  safety_identifier?: string;\n  seed?: number;\n  service_tier?: 'auto' | 'default' | 'flex' | 'scale' | 'priority';\n  stop?: string | string[];\n  store?: boolean;\n  temperature?: number;\n  top_logprobs?: number;\n  top_p?: number;\n  user?: string;\n  verbosity?: Verbosity;\n  web_search_options?: WebSearchOptions;\n\n  // livekit-typed arguments\n  tool_choice?: ToolChoice;\n  // TODO(brian): support response format\n  // response_format?: OpenAI.Chat.Completions.ChatCompletionCreateParams['response_format']\n}\n\nexport type LLMModels =\n  | OpenAIModels\n  | GoogleModels\n  | QwenModels\n  | KimiModels\n  | DeepSeekModels\n  | AnyString;\n\nexport interface InferenceLLMOptions {\n  model: LLMModels;\n  provider?: string;\n  baseURL: string;\n  apiKey: string;\n  apiSecret: string;\n  modelOptions: ChatCompletionOptions;\n  strictToolSchema?: boolean;\n}\n\nexport interface GatewayOptions {\n  apiKey: string;\n  apiSecret: string;\n}\n\n/**\n * Livekit Cloud Inference LLM\n */\nexport class LLM extends llm.LLM {\n  private client: OpenAI;\n  private opts: InferenceLLMOptions;\n\n  constructor(opts: {\n    model: LLMModels;\n    provider?: string;\n    baseURL?: string;\n    apiKey?: string;\n    apiSecret?: string;\n    modelOptions?: InferenceLLMOptions['modelOptions'];\n    strictToolSchema?: boolean;\n  }) {\n    super();\n\n    const {\n      model,\n      provider,\n      baseURL,\n      apiKey,\n      apiSecret,\n      modelOptions,\n      strictToolSchema = false,\n    } = opts;\n\n    const lkBaseURL = baseURL || process.env.LIVEKIT_INFERENCE_URL || DEFAULT_BASE_URL;\n    const lkApiKey = apiKey || process.env.LIVEKIT_INFERENCE_API_KEY || process.env.LIVEKIT_API_KEY;\n    if (!lkApiKey) {\n      throw new Error('apiKey is required: pass apiKey or set LIVEKIT_API_KEY');\n    }\n\n    const lkApiSecret =\n      apiSecret || process.env.LIVEKIT_INFERENCE_API_SECRET || process.env.LIVEKIT_API_SECRET;\n    if (!lkApiSecret) {\n      throw new Error('apiSecret is required: pass apiSecret or set LIVEKIT_API_SECRET');\n    }\n\n    this.opts = {\n      model,\n      provider,\n      baseURL: lkBaseURL,\n      apiKey: lkApiKey,\n      apiSecret: lkApiSecret,\n      modelOptions: modelOptions || {},\n      strictToolSchema,\n    };\n\n    this.client = new OpenAI({\n      baseURL: this.opts.baseURL,\n      apiKey: '', // leave a temporary empty string to avoid OpenAI complain about missing key\n    });\n  }\n\n  label(): string {\n    return 'inference.LLM';\n  }\n\n  get model(): string {\n    return this.opts.model;\n  }\n\n  static fromModelString(modelString: string): LLM {\n    return new LLM({ model: modelString });\n  }\n\n  chat({\n    chatCtx,\n    toolCtx,\n    connOptions = DEFAULT_API_CONNECT_OPTIONS,\n    parallelToolCalls,\n    toolChoice,\n    // TODO(AJS-270): Add response_format parameter support\n    extraKwargs,\n  }: {\n    chatCtx: llm.ChatContext;\n    toolCtx?: llm.ToolContext;\n    connOptions?: APIConnectOptions;\n    parallelToolCalls?: boolean;\n    toolChoice?: llm.ToolChoice;\n    // TODO(AJS-270): Add responseFormat parameter\n    extraKwargs?: Record<string, unknown>;\n  }): LLMStream {\n    let modelOptions: Record<string, unknown> = { ...(extraKwargs || {}) };\n\n    parallelToolCalls =\n      parallelToolCalls !== undefined\n        ? parallelToolCalls\n        : this.opts.modelOptions.parallel_tool_calls;\n\n    if (toolCtx && Object.keys(toolCtx).length > 0 && parallelToolCalls !== undefined) {\n      modelOptions.parallel_tool_calls = parallelToolCalls;\n    }\n\n    toolChoice =\n      toolChoice !== undefined\n        ? toolChoice\n        : (this.opts.modelOptions.tool_choice as llm.ToolChoice | undefined);\n\n    if (toolChoice) {\n      modelOptions.tool_choice = toolChoice as ToolChoice;\n    }\n\n    // TODO(AJS-270): Add response_format support here\n\n    modelOptions = { ...modelOptions, ...this.opts.modelOptions };\n\n    return new LLMStream(this, {\n      model: this.opts.model,\n      provider: this.opts.provider,\n      client: this.client,\n      chatCtx,\n      toolCtx,\n      connOptions,\n      modelOptions,\n      strictToolSchema: this.opts.strictToolSchema ?? false, // default to false if not set\n      gatewayOptions: {\n        apiKey: this.opts.apiKey,\n        apiSecret: this.opts.apiSecret,\n      },\n    });\n  }\n}\n\nexport class LLMStream extends llm.LLMStream {\n  private model: LLMModels;\n  private provider?: string;\n  private providerFmt: llm.ProviderFormat;\n  private client: OpenAI;\n  private modelOptions: Record<string, unknown>;\n  private strictToolSchema: boolean;\n\n  private gatewayOptions?: GatewayOptions;\n  private toolCallId?: string;\n  private toolIndex?: number;\n  private fncName?: string;\n  private fncRawArguments?: string;\n  private toolExtra?: Record<string, unknown>;\n\n  constructor(\n    llm: LLM,\n    {\n      model,\n      provider,\n      client,\n      chatCtx,\n      toolCtx,\n      gatewayOptions,\n      connOptions,\n      modelOptions,\n      providerFmt,\n      strictToolSchema,\n    }: {\n      model: LLMModels;\n      provider?: string;\n      client: OpenAI;\n      chatCtx: llm.ChatContext;\n      toolCtx?: llm.ToolContext;\n      gatewayOptions?: GatewayOptions;\n      connOptions: APIConnectOptions;\n      modelOptions: Record<string, unknown>;\n      providerFmt?: llm.ProviderFormat;\n      strictToolSchema: boolean;\n    },\n  ) {\n    super(llm, { chatCtx, toolCtx, connOptions });\n    this.client = client;\n    this.gatewayOptions = gatewayOptions;\n    this.provider = provider;\n    this.providerFmt = providerFmt || 'openai';\n    this.modelOptions = modelOptions;\n    this.model = model;\n    this.strictToolSchema = strictToolSchema;\n  }\n\n  protected async run(): Promise<void> {\n    // current function call that we're waiting for full completion (args are streamed)\n    // (defined inside the run method to make sure the state is reset for each run/attempt)\n    let retryable = true;\n    this.toolCallId = this.fncName = this.fncRawArguments = this.toolIndex = undefined;\n    this.toolExtra = undefined;\n\n    try {\n      const messages = (await this.chatCtx.toProviderFormat(\n        this.providerFmt,\n      )) as OpenAI.ChatCompletionMessageParam[];\n\n      const tools = this.toolCtx\n        ? Object.entries(this.toolCtx).map(([name, func]) => {\n            const oaiParams = {\n              type: 'function' as const,\n              function: {\n                name,\n                description: func.description,\n                parameters: llm.toJsonSchema(\n                  func.parameters,\n                  true,\n                  this.strictToolSchema,\n                ) as unknown as OpenAI.Chat.Completions.ChatCompletionFunctionTool['function']['parameters'],\n              } as OpenAI.Chat.Completions.ChatCompletionFunctionTool['function'],\n            };\n\n            if (this.strictToolSchema) {\n              oaiParams.function.strict = true;\n            }\n\n            return oaiParams;\n          })\n        : undefined;\n\n      const requestOptions: Record<string, unknown> = { ...this.modelOptions };\n      if (!tools) {\n        delete requestOptions.tool_choice;\n      }\n\n      // Dynamically set the access token for the LiveKit Agent Gateway API\n      if (this.gatewayOptions) {\n        this.client.apiKey = await createAccessToken(\n          this.gatewayOptions.apiKey,\n          this.gatewayOptions.apiSecret,\n        );\n      }\n\n      if (this.provider) {\n        const extraHeaders = requestOptions.extra_headers\n          ? (requestOptions.extra_headers as Record<string, string>)\n          : {};\n        extraHeaders['X-LiveKit-Inference-Provider'] = this.provider;\n        requestOptions.extra_headers = extraHeaders;\n      }\n\n      const stream = await this.client.chat.completions.create(\n        {\n          model: this.model,\n          messages,\n          tools,\n          stream: true,\n          stream_options: { include_usage: true },\n          ...requestOptions,\n        },\n        {\n          timeout: this.connOptions.timeoutMs,\n        },\n      );\n\n      for await (const chunk of stream) {\n        for (const choice of chunk.choices) {\n          if (this.abortController.signal.aborted) {\n            break;\n          }\n          const chatChunk = this.parseChoice(chunk.id, choice);\n          if (chatChunk) {\n            retryable = false;\n            this.queue.put(chatChunk);\n          }\n        }\n\n        if (chunk.usage) {\n          const usage = chunk.usage;\n          retryable = false;\n          this.queue.put({\n            id: chunk.id,\n            usage: {\n              completionTokens: usage.completion_tokens,\n              promptTokens: usage.prompt_tokens,\n              promptCachedTokens: usage.prompt_tokens_details?.cached_tokens || 0,\n              totalTokens: usage.total_tokens,\n            },\n          });\n        }\n      }\n    } catch (error) {\n      if (error instanceof OpenAI.APIConnectionTimeoutError) {\n        throw new APITimeoutError({ options: { retryable } });\n      } else if (error instanceof OpenAI.APIError) {\n        throw new APIStatusError({\n          message: error.message,\n          options: {\n            statusCode: error.status,\n            body: error.error,\n            requestId: error.requestID,\n            retryable,\n          },\n        });\n      } else {\n        throw new APIConnectionError({\n          message: toError(error).message,\n          options: { retryable },\n        });\n      }\n    }\n  }\n\n  private parseChoice(\n    id: string,\n    choice: OpenAI.ChatCompletionChunk.Choice,\n  ): llm.ChatChunk | undefined {\n    const delta = choice.delta;\n\n    // https://github.com/livekit/agents/issues/688\n    // the delta can be None when using Azure OpenAI (content filtering)\n    if (delta === undefined) return undefined;\n\n    if (delta.tool_calls) {\n      // check if we have functions to calls\n      for (const tool of delta.tool_calls) {\n        if (!tool.function) {\n          continue; // oai may add other tools in the future\n        }\n\n        /**\n         * The way OpenAI streams tool calls is a bit tricky.\n         *\n         * For any new tool call, it first emits a delta tool call with id, and function name,\n         * the rest of the delta chunks will only stream the remaining arguments string,\n         * until a new tool call is started or the tool call is finished.\n         * See below for an example.\n         *\n         * Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role='assistant', tool_calls=None), finish_reason=None, index=0, logprobs=None)\n         * [ChoiceDeltaToolCall(index=0, id='call_LaVeHWUHpef9K1sd5UO8TtLg', function=ChoiceDeltaToolCallFunction(arguments='', name='get_weather'), type='function')]\n         * [ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='\\{\"location\": \"P', name=None), type=None)]\n         * [ChoiceDeltaToolCall(index=0, id=None, function=ChoiceDeltaToolCallFunction(arguments='aris\\}', name=None), type=None)]\n         * [ChoiceDeltaToolCall(index=1, id='call_ThU4OmMdQXnnVmpXGOCknXIB', function=ChoiceDeltaToolCallFunction(arguments='', name='get_weather'), type='function')]\n         * [ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='\\{\"location\": \"T', name=None), type=None)]\n         * [ChoiceDeltaToolCall(index=1, id=None, function=ChoiceDeltaToolCallFunction(arguments='okyo', name=None), type=None)]\n         * Choice(delta=ChoiceDelta(content=None, function_call=None, refusal=None, role=None, tool_calls=None), finish_reason='tool_calls', index=0, logprobs=None)\n         */\n        let callChunk: llm.ChatChunk | undefined;\n        // If we have a previous tool call and this is a new one, emit the previous\n        if (this.toolCallId && tool.id && tool.index !== this.toolIndex) {\n          callChunk = this.createRunningToolCallChunk(id, delta);\n          this.toolCallId = this.fncName = this.fncRawArguments = undefined;\n          this.toolExtra = undefined;\n        }\n\n        // Start or continue building the current tool call\n        if (tool.function.name) {\n          this.toolIndex = tool.index;\n          this.toolCallId = tool.id;\n          this.fncName = tool.function.name;\n          this.fncRawArguments = tool.function.arguments || '';\n          // Extract extra from tool call (e.g., Google thought signatures)\n          this.toolExtra =\n            // eslint-disable-next-line @typescript-eslint/no-explicit-any\n            ((tool as any).extra_content as Record<string, unknown> | undefined) ?? undefined;\n        } else if (tool.function.arguments) {\n          this.fncRawArguments = (this.fncRawArguments || '') + tool.function.arguments;\n        }\n\n        if (callChunk) {\n          return callChunk;\n        }\n      }\n    }\n\n    // If we're done with tool calls, emit the final one\n    if (\n      choice.finish_reason &&\n      ['tool_calls', 'stop'].includes(choice.finish_reason) &&\n      this.toolCallId !== undefined\n    ) {\n      const callChunk = this.createRunningToolCallChunk(id, delta);\n      this.toolCallId = this.fncName = this.fncRawArguments = undefined;\n      this.toolExtra = undefined;\n      return callChunk;\n    }\n\n    // Extract extra from delta (e.g., Google thought signatures on text parts)\n    const deltaExtra =\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      ((delta as any).extra_content as Record<string, unknown> | undefined) ?? undefined;\n\n    // Regular content message\n    if (!delta.content && !deltaExtra) {\n      return undefined;\n    }\n\n    return {\n      id,\n      delta: {\n        role: 'assistant',\n        content: delta.content || undefined,\n        extra: deltaExtra,\n      },\n    };\n  }\n\n  private createRunningToolCallChunk(\n    id: string,\n    delta: OpenAI.Chat.Completions.ChatCompletionChunk.Choice.Delta,\n  ): llm.ChatChunk {\n    const toolExtra = this.toolExtra ? { ...this.toolExtra } : {};\n    const thoughtSignature = this.extractThoughtSignature(toolExtra);\n    const deltaExtra =\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      ((delta as any).extra_content as Record<string, unknown> | undefined) ?? undefined;\n\n    return {\n      id,\n      delta: {\n        role: 'assistant',\n        content: delta.content || undefined,\n        extra: deltaExtra,\n        toolCalls: [\n          llm.FunctionCall.create({\n            callId: this.toolCallId || '',\n            name: this.fncName || '',\n            args: this.fncRawArguments || '',\n            extra: toolExtra,\n            thoughtSignature,\n          }),\n        ],\n      },\n    };\n  }\n\n  private extractThoughtSignature(extra?: Record<string, unknown>): string | undefined {\n    const googleExtra = extra?.google;\n    if (googleExtra && typeof googleExtra === 'object') {\n      // eslint-disable-next-line @typescript-eslint/no-explicit-any\n      return (googleExtra as any).thoughtSignature || (googleExtra as any).thought_signature;\n    }\n    return undefined;\n  }\n}\n"],"mappings":";;;;;;;;;;;;;;;;;;;;;;;;;;;;AAAA;AAAA;AAAA;AAAA;AAAA;AAAA;AAGA,oBAAmB;AACnB,eAOO;AACP,UAAqB;AAErB,mBAAkD;AAElD,MAAM,mBAAmB;AA4FlB,MAAM,YAAY,IAAI,IAAI;AAAA,EACvB;AAAA,EACA;AAAA,EAER,YAAY,MAQT;AACD,UAAM;AAEN,UAAM;AAAA,MACJ;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,mBAAmB;AAAA,IACrB,IAAI;AAEJ,UAAM,YAAY,WAAW,QAAQ,IAAI,yBAAyB;AAClE,UAAM,WAAW,UAAU,QAAQ,IAAI,6BAA6B,QAAQ,IAAI;AAChF,QAAI,CAAC,UAAU;AACb,YAAM,IAAI,MAAM,wDAAwD;AAAA,IAC1E;AAEA,UAAM,cACJ,aAAa,QAAQ,IAAI,gCAAgC,QAAQ,IAAI;AACvE,QAAI,CAAC,aAAa;AAChB,YAAM,IAAI,MAAM,iEAAiE;AAAA,IACnF;AAEA,SAAK,OAAO;AAAA,MACV;AAAA,MACA;AAAA,MACA,SAAS;AAAA,MACT,QAAQ;AAAA,MACR,WAAW;AAAA,MACX,cAAc,gBAAgB,CAAC;AAAA,MAC/B;AAAA,IACF;AAEA,SAAK,SAAS,IAAI,cAAAA,QAAO;AAAA,MACvB,SAAS,KAAK,KAAK;AAAA,MACnB,QAAQ;AAAA;AAAA,IACV,CAAC;AAAA,EACH;AAAA,EAEA,QAAgB;AACd,WAAO;AAAA,EACT;AAAA,EAEA,IAAI,QAAgB;AAClB,WAAO,KAAK,KAAK;AAAA,EACnB;AAAA,EAEA,OAAO,gBAAgB,aAA0B;AAC/C,WAAO,IAAI,IAAI,EAAE,OAAO,YAAY,CAAC;AAAA,EACvC;AAAA,EAEA,KAAK;AAAA,IACH;AAAA,IACA;AAAA,IACA,cAAc;AAAA,IACd;AAAA,IACA;AAAA;AAAA,IAEA;AAAA,EACF,GAQc;AACZ,QAAI,eAAwC,EAAE,GAAI,eAAe,CAAC,EAAG;AAErE,wBACE,sBAAsB,SAClB,oBACA,KAAK,KAAK,aAAa;AAE7B,QAAI,WAAW,OAAO,KAAK,OAAO,EAAE,SAAS,KAAK,sBAAsB,QAAW;AACjF,mBAAa,sBAAsB;AAAA,IACrC;AAEA,iBACE,eAAe,SACX,aACC,KAAK,KAAK,aAAa;AAE9B,QAAI,YAAY;AACd,mBAAa,cAAc;AAAA,IAC7B;AAIA,mBAAe,EAAE,GAAG,cAAc,GAAG,KAAK,KAAK,aAAa;AAE5D,WAAO,IAAI,UAAU,MAAM;AAAA,MACzB,OAAO,KAAK,KAAK;AAAA,MACjB,UAAU,KAAK,KAAK;AAAA,MACpB,QAAQ,KAAK;AAAA,MACb;AAAA,MACA;AAAA,MACA;AAAA,MACA;AAAA,MACA,kBAAkB,KAAK,KAAK,oBAAoB;AAAA;AAAA,MAChD,gBAAgB;AAAA,QACd,QAAQ,KAAK,KAAK;AAAA,QAClB,WAAW,KAAK,KAAK;AAAA,MACvB;AAAA,IACF,CAAC;AAAA,EACH;AACF;AAEO,MAAM,kBAAkB,IAAI,UAAU;AAAA,EACnC;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAEA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EACA;AAAA,EAER,YACEC,MACA;AAAA,IACE;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,IACA;AAAA,EACF,GAYA;AACA,UAAMA,MAAK,EAAE,SAAS,SAAS,YAAY,CAAC;AAC5C,SAAK,SAAS;AACd,SAAK,iBAAiB;AACtB,SAAK,WAAW;AAChB,SAAK,cAAc,eAAe;AAClC,SAAK,eAAe;AACpB,SAAK,QAAQ;AACb,SAAK,mBAAmB;AAAA,EAC1B;AAAA,EAEA,MAAgB,MAAqB;AA1RvC;AA6RI,QAAI,YAAY;AAChB,SAAK,aAAa,KAAK,UAAU,KAAK,kBAAkB,KAAK,YAAY;AACzE,SAAK,YAAY;AAEjB,QAAI;AACF,YAAM,WAAY,MAAM,KAAK,QAAQ;AAAA,QACnC,KAAK;AAAA,MACP;AAEA,YAAM,QAAQ,KAAK,UACf,OAAO,QAAQ,KAAK,OAAO,EAAE,IAAI,CAAC,CAAC,MAAM,IAAI,MAAM;AACjD,cAAM,YAAY;AAAA,UAChB,MAAM;AAAA,UACN,UAAU;AAAA,YACR;AAAA,YACA,aAAa,KAAK;AAAA,YAClB,YAAY,IAAI;AAAA,cACd,KAAK;AAAA,cACL;AAAA,cACA,KAAK;AAAA,YACP;AAAA,UACF;AAAA,QACF;AAEA,YAAI,KAAK,kBAAkB;AACzB,oBAAU,SAAS,SAAS;AAAA,QAC9B;AAEA,eAAO;AAAA,MACT,CAAC,IACD;AAEJ,YAAM,iBAA0C,EAAE,GAAG,KAAK,aAAa;AACvE,UAAI,CAAC,OAAO;AACV,eAAO,eAAe;AAAA,MACxB;AAGA,UAAI,KAAK,gBAAgB;AACvB,aAAK,OAAO,SAAS,UAAM;AAAA,UACzB,KAAK,eAAe;AAAA,UACpB,KAAK,eAAe;AAAA,QACtB;AAAA,MACF;AAEA,UAAI,KAAK,UAAU;AACjB,cAAM,eAAe,eAAe,gBAC/B,eAAe,gBAChB,CAAC;AACL,qBAAa,8BAA8B,IAAI,KAAK;AACpD,uBAAe,gBAAgB;AAAA,MACjC;AAEA,YAAM,SAAS,MAAM,KAAK,OAAO,KAAK,YAAY;AAAA,QAChD;AAAA,UACE,OAAO,KAAK;AAAA,UACZ;AAAA,UACA;AAAA,UACA,QAAQ;AAAA,UACR,gBAAgB,EAAE,eAAe,KAAK;AAAA,UACtC,GAAG;AAAA,QACL;AAAA,QACA;AAAA,UACE,SAAS,KAAK,YAAY;AAAA,QAC5B;AAAA,MACF;AAEA,uBAAiB,SAAS,QAAQ;AAChC,mBAAW,UAAU,MAAM,SAAS;AAClC,cAAI,KAAK,gBAAgB,OAAO,SAAS;AACvC;AAAA,UACF;AACA,gBAAM,YAAY,KAAK,YAAY,MAAM,IAAI,MAAM;AACnD,cAAI,WAAW;AACb,wBAAY;AACZ,iBAAK,MAAM,IAAI,SAAS;AAAA,UAC1B;AAAA,QACF;AAEA,YAAI,MAAM,OAAO;AACf,gBAAM,QAAQ,MAAM;AACpB,sBAAY;AACZ,eAAK,MAAM,IAAI;AAAA,YACb,IAAI,MAAM;AAAA,YACV,OAAO;AAAA,cACL,kBAAkB,MAAM;AAAA,cACxB,cAAc,MAAM;AAAA,cACpB,sBAAoB,WAAM,0BAAN,mBAA6B,kBAAiB;AAAA,cAClE,aAAa,MAAM;AAAA,YACrB;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAAA,IACF,SAAS,OAAO;AACd,UAAI,iBAAiB,cAAAD,QAAO,2BAA2B;AACrD,cAAM,IAAI,yBAAgB,EAAE,SAAS,EAAE,UAAU,EAAE,CAAC;AAAA,MACtD,WAAW,iBAAiB,cAAAA,QAAO,UAAU;AAC3C,cAAM,IAAI,wBAAe;AAAA,UACvB,SAAS,MAAM;AAAA,UACf,SAAS;AAAA,YACP,YAAY,MAAM;AAAA,YAClB,MAAM,MAAM;AAAA,YACZ,WAAW,MAAM;AAAA,YACjB;AAAA,UACF;AAAA,QACF,CAAC;AAAA,MACH,OAAO;AACL,cAAM,IAAI,4BAAmB;AAAA,UAC3B,aAAS,kBAAQ,KAAK,EAAE;AAAA,UACxB,SAAS,EAAE,UAAU;AAAA,QACvB,CAAC;AAAA,MACH;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,YACN,IACA,QAC2B;AAC3B,UAAM,QAAQ,OAAO;AAIrB,QAAI,UAAU,OAAW,QAAO;AAEhC,QAAI,MAAM,YAAY;AAEpB,iBAAW,QAAQ,MAAM,YAAY;AACnC,YAAI,CAAC,KAAK,UAAU;AAClB;AAAA,QACF;AAmBA,YAAI;AAEJ,YAAI,KAAK,cAAc,KAAK,MAAM,KAAK,UAAU,KAAK,WAAW;AAC/D,sBAAY,KAAK,2BAA2B,IAAI,KAAK;AACrD,eAAK,aAAa,KAAK,UAAU,KAAK,kBAAkB;AACxD,eAAK,YAAY;AAAA,QACnB;AAGA,YAAI,KAAK,SAAS,MAAM;AACtB,eAAK,YAAY,KAAK;AACtB,eAAK,aAAa,KAAK;AACvB,eAAK,UAAU,KAAK,SAAS;AAC7B,eAAK,kBAAkB,KAAK,SAAS,aAAa;AAElD,eAAK;AAAA,UAED,KAAa,iBAAyD;AAAA,QAC5E,WAAW,KAAK,SAAS,WAAW;AAClC,eAAK,mBAAmB,KAAK,mBAAmB,MAAM,KAAK,SAAS;AAAA,QACtE;AAEA,YAAI,WAAW;AACb,iBAAO;AAAA,QACT;AAAA,MACF;AAAA,IACF;AAGA,QACE,OAAO,iBACP,CAAC,cAAc,MAAM,EAAE,SAAS,OAAO,aAAa,KACpD,KAAK,eAAe,QACpB;AACA,YAAM,YAAY,KAAK,2BAA2B,IAAI,KAAK;AAC3D,WAAK,aAAa,KAAK,UAAU,KAAK,kBAAkB;AACxD,WAAK,YAAY;AACjB,aAAO;AAAA,IACT;AAGA,UAAM;AAAA;AAAA,MAEF,MAAc,iBAAyD;AAAA;AAG3E,QAAI,CAAC,MAAM,WAAW,CAAC,YAAY;AACjC,aAAO;AAAA,IACT;AAEA,WAAO;AAAA,MACL;AAAA,MACA,OAAO;AAAA,QACL,MAAM;AAAA,QACN,SAAS,MAAM,WAAW;AAAA,QAC1B,OAAO;AAAA,MACT;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,2BACN,IACA,OACe;AACf,UAAM,YAAY,KAAK,YAAY,EAAE,GAAG,KAAK,UAAU,IAAI,CAAC;AAC5D,UAAM,mBAAmB,KAAK,wBAAwB,SAAS;AAC/D,UAAM;AAAA;AAAA,MAEF,MAAc,iBAAyD;AAAA;AAE3E,WAAO;AAAA,MACL;AAAA,MACA,OAAO;AAAA,QACL,MAAM;AAAA,QACN,SAAS,MAAM,WAAW;AAAA,QAC1B,OAAO;AAAA,QACP,WAAW;AAAA,UACT,IAAI,aAAa,OAAO;AAAA,YACtB,QAAQ,KAAK,cAAc;AAAA,YAC3B,MAAM,KAAK,WAAW;AAAA,YACtB,MAAM,KAAK,mBAAmB;AAAA,YAC9B,OAAO;AAAA,YACP;AAAA,UACF,CAAC;AAAA,QACH;AAAA,MACF;AAAA,IACF;AAAA,EACF;AAAA,EAEQ,wBAAwB,OAAqD;AACnF,UAAM,cAAc,+BAAO;AAC3B,QAAI,eAAe,OAAO,gBAAgB,UAAU;AAElD,aAAQ,YAAoB,oBAAqB,YAAoB;AAAA,IACvE;AACA,WAAO;AAAA,EACT;AACF;","names":["OpenAI","llm"]}