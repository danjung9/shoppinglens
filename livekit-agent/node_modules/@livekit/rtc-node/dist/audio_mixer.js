import { AsyncQueue } from "./async_queue.js";
import { AudioFrame } from "./audio_frame.js";
import { log } from "./log.js";
import { AsyncQueue as AsyncQueue2 } from "./async_queue.js";
class AudioMixer {
  /**
   * Initialize the AudioMixer.
   *
   * @param sampleRate - The audio sample rate in Hz.
   * @param numChannels - The number of audio channels.
   * @param options - Optional configuration for the mixer.
   */
  constructor(sampleRate, numChannels, options = {}) {
    this.streams = /* @__PURE__ */ new Set();
    this.buffers = /* @__PURE__ */ new Map();
    this.streamIterators = /* @__PURE__ */ new Map();
    this.sampleRate = sampleRate;
    this.numChannels = numChannels;
    this.chunkSize = options.blocksize && options.blocksize > 0 ? options.blocksize : Math.floor(sampleRate / 10);
    this.streamTimeoutMs = options.streamTimeoutMs ?? 100;
    this.queue = new AsyncQueue(options.capacity ?? 100);
    this.streamSignal = new AsyncQueue(1);
    this.ending = false;
    this.closed = false;
    this.mixerTask = this.mixer();
  }
  /**
   * Add an audio stream to the mixer.
   *
   * The stream is added to the internal set of streams and an empty buffer is initialized for it,
   * if not already present.
   *
   * @param stream - An async iterable that produces AudioFrame objects.
   * @throws Error if the mixer has been closed.
   */
  addStream(stream) {
    if (this.ending) {
      throw new Error("Cannot add stream after mixer has been closed");
    }
    this.streams.add(stream);
    if (!this.buffers.has(stream)) {
      this.buffers.set(stream, new Int16Array(0));
    }
    this.streamSignal.put(void 0).catch(() => {
    });
  }
  /**
   * Remove an audio stream from the mixer.
   *
   * This method removes the specified stream and its associated buffer from the mixer.
   *
   * @param stream - The audio stream to remove.
   */
  removeStream(stream) {
    this.streams.delete(stream);
    this.buffers.delete(stream);
    this.streamIterators.delete(stream);
  }
  /**
   * Returns an async iterator for the mixed audio frames.
   */
  [Symbol.asyncIterator]() {
    return {
      next: async () => {
        const frame = await this.getNextFrame();
        if (frame === null) {
          return { done: true, value: void 0 };
        }
        return { done: false, value: frame };
      }
    };
  }
  /**
   * Immediately stop mixing and close the mixer.
   *
   * This stops the mixing task, and any unconsumed output in the queue may be dropped.
   */
  async aclose() {
    if (this.closed) {
      return;
    }
    this.closed = true;
    this.ending = true;
    this.streamSignal.close();
    this.queue.close();
    await this.mixerTask;
  }
  /**
   * Signal that no more streams will be added.
   *
   * This method marks the mixer as closed so that it flushes any remaining buffered output before ending.
   * Note that existing streams will still be processed until exhausted.
   */
  endInput() {
    this.ending = true;
  }
  async getNextFrame() {
    while (true) {
      const frame = this.queue.get();
      if (frame !== void 0) {
        return frame;
      }
      if (this.queue.closed || this.ending && this.streams.size === 0) {
        return null;
      }
      await this.queue.waitForItem();
    }
  }
  async mixer() {
    while (true) {
      if (this.ending && this.streams.size === 0) {
        break;
      }
      if (this.streams.size === 0) {
        await this.streamSignal.waitForItem();
        this.streamSignal.get();
        continue;
      }
      const streamArray = Array.from(this.streams);
      const promises = streamArray.map((stream) => this.getContribution(stream));
      const results = await Promise.all(
        promises.map(
          (p) => p.then((value) => ({ status: "fulfilled", value })).catch((reason) => ({ status: "rejected", reason }))
        )
      );
      const contributions = [];
      let anyData = false;
      const removals = [];
      for (const result of results) {
        if (result.status !== "fulfilled") {
          log.warn("AudioMixer: Stream contribution failed:", result.reason);
          continue;
        }
        const contrib = result.value;
        contributions.push(contrib.data);
        this.buffers.set(contrib.stream, contrib.buffer);
        if (contrib.hadData) {
          anyData = true;
        }
        if (contrib.exhausted && contrib.buffer.length === 0) {
          removals.push(contrib.stream);
        }
      }
      for (const stream of removals) {
        this.removeStream(stream);
      }
      if (!this.ending && removals.length > 0 && this.streams.size === 0) {
        this.ending = true;
      }
      if (!anyData) {
        await this.sleep(1);
        continue;
      }
      const mixed = this.mixAudio(contributions);
      const frame = new AudioFrame(mixed, this.sampleRate, this.numChannels, this.chunkSize);
      if (this.closed) {
        break;
      }
      try {
        await this.queue.put(frame);
      } catch {
        break;
      }
    }
    this.queue.close();
  }
  async getContribution(stream) {
    let buf = this.buffers.get(stream) ?? new Int16Array(0);
    const initialBufferLength = buf.length;
    let exhausted = false;
    let receivedDataInThisCall = false;
    let iterator = this.streamIterators.get(stream);
    if (!iterator) {
      iterator = stream[Symbol.asyncIterator]();
      this.streamIterators.set(stream, iterator);
    }
    while (buf.length < this.chunkSize * this.numChannels && !exhausted && !this.closed) {
      try {
        const result = await Promise.race([iterator.next(), this.timeout(this.streamTimeoutMs)]);
        if (result === "timeout") {
          console.warn(`AudioMixer: stream timeout after ${this.streamTimeoutMs}ms`);
          break;
        }
        if (result.done) {
          exhausted = true;
          break;
        }
        const frame = result.value;
        const newData = frame.data;
        receivedDataInThisCall = true;
        if (buf.length === 0) {
          buf = newData;
        } else {
          const combined = new Int16Array(buf.length + newData.length);
          combined.set(buf);
          combined.set(newData, buf.length);
          buf = combined;
        }
      } catch (error) {
        console.error(`AudioMixer: Error reading from stream:`, error);
        exhausted = true;
        break;
      }
    }
    let contrib;
    const samplesNeeded = this.chunkSize * this.numChannels;
    if (buf.length >= samplesNeeded) {
      contrib = buf.subarray(0, samplesNeeded);
      buf = buf.subarray(samplesNeeded);
    } else {
      const padded = new Int16Array(samplesNeeded);
      padded.set(buf);
      contrib = padded;
      buf = new Int16Array(0);
    }
    const hadData = initialBufferLength > 0 || receivedDataInThisCall || buf.length > 0;
    return {
      stream,
      data: contrib,
      buffer: buf,
      hadData,
      exhausted
    };
  }
  mixAudio(contributions) {
    if (contributions.length === 0) {
      return new Int16Array(this.chunkSize * this.numChannels);
    }
    const length = this.chunkSize * this.numChannels;
    const acc = new Int32Array(length);
    for (const contrib of contributions) {
      for (let i = 0; i < length; i++) {
        const val = contrib[i];
        if (val !== void 0) {
          acc[i] = (acc[i] ?? 0) + val;
        }
      }
    }
    const mixed = new Int16Array(length);
    for (let i = 0; i < length; i++) {
      const val = acc[i] ?? 0;
      if (val > 32767) {
        mixed[i] = 32767;
      } else if (val < -32768) {
        mixed[i] = -32768;
      } else {
        mixed[i] = val;
      }
    }
    return mixed;
  }
  sleep(ms) {
    return new Promise((resolve) => setTimeout(resolve, ms));
  }
  timeout(ms) {
    return new Promise((resolve) => setTimeout(() => resolve("timeout"), ms));
  }
}
export {
  AsyncQueue2 as AsyncQueue,
  AudioMixer
};
//# sourceMappingURL=audio_mixer.js.map